{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 7286.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18_with_dropout\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 6697.21it/s]\n"
     ]
    }
   ],
   "source": [
    "####### dropout resnet18 vs without dropout\n",
    "#### \n",
    "import torch\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "sys.path.append(\"/home/yifan/projects/cophi/ContraVis\")\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/yifan/projects/deepdebugertool/DLVisDebugger\")\n",
    "# REF_PATH = \"/home/yifan/Exp/Noise/0.2/experiment_vis\"\n",
    "# CONFIG_PATH = \"/home/yifan/experiments/noise/20\"\n",
    "# TAR_PATH = \"/home/yifan/dataset/cleanfornoise10\"\n",
    "\n",
    "# # CLEAN_PATH = \"/home/yifan/Exp/Noise/0.2/experiment1\"\n",
    "TAR_PATH = \"/home/yifan/dataset/resnet18_with_dropout/pairflip/cifar10/0\"\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "\n",
    "\n",
    "ENCODER_DIMS=[512,256,256,256,256,2]\n",
    "DECODER_DIMS= [2,256,256,256,256,512]\n",
    "VIS_MODEL_NAME = 'vis2'\n",
    "\n",
    "########## initulize reference data and target data\n",
    "from singleVis.DataInit import DataInit\n",
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "DEVICE = \"cuda:1\"\n",
    "tar_datainit = DataInit(TAR_PATH,TAR_PATH,TAR_EPOCH,DEVICE)\n",
    "ref_datainit = DataInit(REF_PATH,REF_PATH,REF_EPOCH,DEVICE)\n",
    "\n",
    "ref_model, ref_provider, ref_train_data, ref_prediction, ref_prediction_res, ref_scores = ref_datainit.getData()\n",
    "tar_model, tar_provider, tar_train_data, tar_prediction, tar_prediction_res, tar_scores = tar_datainit.getData()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512)\n",
      "(50000, 512)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import svd  \n",
    "def orthogonal_mapping(data1, data2):\n",
    "        \"\"\"\n",
    "        use Orthogonal Mapping, map data2 to data1's space。\n",
    "    \n",
    "        :param data1: numpy array, shape (n_samples, n_features)\n",
    "        :param data2: numpy array, shape (n_samples, n_features)\n",
    "        :return: data2_mapped: numpy array, mapped data2\n",
    "        \"\"\"\n",
    "        # step1: Centralized data\n",
    "        data1_centered = data1 - np.mean(data1, axis=0)\n",
    "        data2_centered = data2 - np.mean(data2, axis=0)\n",
    "        # step2: Calculate the cross-covariance matrix\n",
    "        C = data2_centered.T @ data1_centered\n",
    "        # step3: singular value decomposition\n",
    "        U, _, Vt = svd(C)\n",
    "\n",
    "        # step4: Compute orthogonal mapping matrix\n",
    "        W = U @ Vt\n",
    "\n",
    "        # step5: Apply mapping matrix\n",
    "        data2_mapped = data2_centered @ W\n",
    "    \n",
    "        return data2_mapped\n",
    "X_train1 = ref_provider.train_representation(REF_EPOCH)\n",
    "X_train2 = tar_provider.train_representation(TAR_EPOCH)\n",
    "X_train2 = X_train2.reshape(X_train2.shape[0],X_train2.shape[1])\n",
    "print(X_train1.shape)\n",
    "print(X_train2.shape)\n",
    "data2_mapped = orthogonal_mapping(X_train1,X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999986666666667\n"
     ]
    }
   ],
   "source": [
    "from eval.evaluate import *\n",
    "rate = evaluate_high_dimesion_trans_knn_preserving(data2_mapped, X_train2)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_203350/3701356828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformationTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtarns_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar_mapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_reconstructed\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation_train_advanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/cophi/ContraVis/contrast/transfomration.py\u001b[0m in \u001b[0;36mtransformation_train_advanced\u001b[0;34m(self, lambda_translation, lambda_similarity, num_epochs, lr, sample_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransformation_train_advanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_translation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_similarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtar_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/cophi/ContraVis/contrast/transfomration.py\u001b[0m in \u001b[0;36mcompute_similarity_matrix\u001b[0;34m(self, data, sample_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mnbrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "from contrast.transfomration import TransformationTrainer\n",
    "\n",
    "trainer = TransformationTrainer(X_train1,X_train2, DEVICE)\n",
    "tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train_advanced()\n",
    "# tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 7558.12it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 7079.62it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_pred = ref_provider.get_pred(REF_EPOCH, X_train1).argmax(axis=1)\n",
    "tar_pred = tar_provider.get_pred(TAR_EPOCH, X_train2).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49024933333333337\n"
     ]
    }
   ],
   "source": [
    "from eval.evaluate import *\n",
    "rate = evaluate_high_dimesion_trans_knn_preserving(tar_mapped, X_train2)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 6842.17it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reconstructed_pred = tar_provider.get_pred(TAR_EPOCH, ref_reconstructed).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "diff = 0\n",
    "for i in range(len(reconstructed_pred)):\n",
    "    if reconstructed_pred[i] != tar_pred[i]:\n",
    "        diff = diff+1\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff pred number is 41\n",
      "index diff pred number is 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "sub_len = 50000\n",
    "\n",
    "# 1. use cos sim build \n",
    "model = NearestNeighbors(n_neighbors=1, metric='cosine', algorithm='auto').fit(tar_mapped[:sub_len])\n",
    "\n",
    "# 2. find X_train1 most sim point data2_mapped中的最相似点\n",
    "distances, most_similar_points = model.kneighbors(X_train1[:sub_len])\n",
    "\n",
    "most_similar_points = most_similar_points.flatten()  # 将索引数组转为1D\n",
    "\n",
    "# 3. 比较预测值\n",
    "m = np.sum(ref_pred[:sub_len] != tar_pred[most_similar_points])\n",
    "k = np.sum(ref_pred[:sub_len] != tar_pred[:sub_len])\n",
    "\n",
    "print(\"diff pred number is {}\".format(m))\n",
    "print(\"index diff pred number is {}\".format(k))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
