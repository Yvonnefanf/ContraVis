{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 431.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18_with_dropout\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 6561.84it/s]\n"
     ]
    }
   ],
   "source": [
    "####### dropout resnet18 vs without dropout\n",
    "#### \n",
    "import torch\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "sys.path.append(\"/home/yifan/projects/cophi/ContraVis\")\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/yifan/projects/deepdebugertool/DLVisDebugger\")\n",
    "# REF_PATH = \"/home/yifan/Exp/Noise/0.2/experiment_vis\"\n",
    "# CONFIG_PATH = \"/home/yifan/experiments/noise/20\"\n",
    "# TAR_PATH = \"/home/yifan/dataset/cleanfornoise10\"\n",
    "\n",
    "# # CLEAN_PATH = \"/home/yifan/Exp/Noise/0.2/experiment1\"\n",
    "TAR_PATH = \"/home/yifan/dataset/resnet18_with_dropout/pairflip/cifar10/0\"\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "\n",
    "\n",
    "ENCODER_DIMS=[512,256,256,256,256,2]\n",
    "DECODER_DIMS= [2,256,256,256,256,512]\n",
    "VIS_MODEL_NAME = 'vis2'\n",
    "\n",
    "########## initulize reference data and target data\n",
    "from singleVis.DataInit import DataInit\n",
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "DEVICE = \"cuda:1\"\n",
    "tar_datainit = DataInit(TAR_PATH,TAR_PATH,TAR_EPOCH,DEVICE)\n",
    "ref_datainit = DataInit(REF_PATH,REF_PATH,REF_EPOCH,DEVICE)\n",
    "\n",
    "ref_model, ref_provider, ref_train_data, ref_prediction, ref_prediction_res, ref_scores = ref_datainit.getData()\n",
    "tar_model, tar_provider, tar_train_data, tar_prediction, tar_prediction_res, tar_scores = tar_datainit.getData()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512)\n",
      "(50000, 512)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import svd  \n",
    "def orthogonal_mapping(data1, data2):\n",
    "        \"\"\"\n",
    "        use Orthogonal Mapping, map data2 to data1's space。\n",
    "    \n",
    "        :param data1: numpy array, shape (n_samples, n_features)\n",
    "        :param data2: numpy array, shape (n_samples, n_features)\n",
    "        :return: data2_mapped: numpy array, mapped data2\n",
    "        \"\"\"\n",
    "        # step1: Centralized data\n",
    "        data1_centered = data1 - np.mean(data1, axis=0)\n",
    "        data2_centered = data2 - np.mean(data2, axis=0)\n",
    "        # step2: Calculate the cross-covariance matrix\n",
    "        C = data2_centered.T @ data1_centered\n",
    "        # step3: singular value decomposition\n",
    "        U, _, Vt = svd(C)\n",
    "\n",
    "        # step4: Compute orthogonal mapping matrix\n",
    "        W = U @ Vt\n",
    "\n",
    "        # step5: Apply mapping matrix\n",
    "        data2_mapped = data2_centered @ W\n",
    "    \n",
    "        return data2_mapped\n",
    "X_train1 = ref_provider.train_representation(REF_EPOCH)\n",
    "X_train2 = tar_provider.train_representation(TAR_EPOCH)\n",
    "X_train2 = X_train2.reshape(X_train2.shape[0],X_train2.shape[1])\n",
    "print(X_train1.shape)\n",
    "print(X_train2.shape)\n",
    "data2_mapped = orthogonal_mapping(X_train1,X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999986666666667\n"
     ]
    }
   ],
   "source": [
    "from eval.evaluate import *\n",
    "rate = evaluate_high_dimesion_trans_knn_preserving(data2_mapped, X_train2)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.4555\n",
      "Epoch [21/30], Loss: 0.7849\n",
      "Epoch [41/30], Loss: 0.6127\n",
      "Epoch [61/30], Loss: 0.3983\n",
      "Epoch [81/30], Loss: 0.2512\n",
      "Epoch [101/30], Loss: 0.2071\n",
      "Epoch [121/30], Loss: 0.1983\n",
      "Epoch [141/30], Loss: 0.1954\n",
      "Epoch [161/30], Loss: 0.1939\n",
      "Epoch [181/30], Loss: 0.1923\n",
      "Epoch [1/30],reconstruction_loss:0.0695,translation_loss:0.2431,neighbor_loss:7.5010, Loss: 7.6921\n",
      "Epoch [2/30],reconstruction_loss:0.0697,translation_loss:0.2431,neighbor_loss:7.4974, Loss: 7.6886\n",
      "Epoch [3/30],reconstruction_loss:0.0698,translation_loss:0.2430,neighbor_loss:7.4968, Loss: 7.6882\n",
      "Epoch [4/30],reconstruction_loss:0.0698,translation_loss:0.2430,neighbor_loss:7.4928, Loss: 7.6841\n",
      "Epoch [5/30],reconstruction_loss:0.0696,translation_loss:0.2429,neighbor_loss:7.4913, Loss: 7.6824\n",
      "Epoch [6/30],reconstruction_loss:0.0694,translation_loss:0.2428,neighbor_loss:7.4881, Loss: 7.6789\n",
      "Epoch [7/30],reconstruction_loss:0.0694,translation_loss:0.2427,neighbor_loss:7.4864, Loss: 7.6772\n",
      "Epoch [8/30],reconstruction_loss:0.0695,translation_loss:0.2427,neighbor_loss:7.4839, Loss: 7.6747\n",
      "Epoch [9/30],reconstruction_loss:0.0695,translation_loss:0.2426,neighbor_loss:7.4806, Loss: 7.6714\n",
      "Epoch [10/30],reconstruction_loss:0.0695,translation_loss:0.2425,neighbor_loss:7.4779, Loss: 7.6687\n",
      "Epoch [11/30],reconstruction_loss:0.0694,translation_loss:0.2425,neighbor_loss:7.4749, Loss: 7.6655\n",
      "Epoch [12/30],reconstruction_loss:0.0693,translation_loss:0.2424,neighbor_loss:7.4732, Loss: 7.6637\n",
      "Epoch [13/30],reconstruction_loss:0.0692,translation_loss:0.2423,neighbor_loss:7.4703, Loss: 7.6607\n",
      "Epoch [14/30],reconstruction_loss:0.0692,translation_loss:0.2423,neighbor_loss:7.4685, Loss: 7.6588\n",
      "Epoch [15/30],reconstruction_loss:0.0692,translation_loss:0.2422,neighbor_loss:7.4655, Loss: 7.6558\n",
      "Epoch [16/30],reconstruction_loss:0.0692,translation_loss:0.2421,neighbor_loss:7.4644, Loss: 7.6547\n",
      "Epoch [17/30],reconstruction_loss:0.0692,translation_loss:0.2421,neighbor_loss:7.4612, Loss: 7.6514\n",
      "Epoch [18/30],reconstruction_loss:0.0691,translation_loss:0.2420,neighbor_loss:7.4596, Loss: 7.6497\n",
      "Epoch [19/30],reconstruction_loss:0.0691,translation_loss:0.2419,neighbor_loss:7.4573, Loss: 7.6474\n",
      "Epoch [20/30],reconstruction_loss:0.0691,translation_loss:0.2419,neighbor_loss:7.4549, Loss: 7.6450\n",
      "Epoch [21/30],reconstruction_loss:0.0692,translation_loss:0.2418,neighbor_loss:7.4523, Loss: 7.6424\n",
      "Epoch [22/30],reconstruction_loss:0.0693,translation_loss:0.2418,neighbor_loss:7.4490, Loss: 7.6392\n",
      "Epoch [23/30],reconstruction_loss:0.0695,translation_loss:0.2417,neighbor_loss:7.4469, Loss: 7.6372\n",
      "Epoch [24/30],reconstruction_loss:0.0698,translation_loss:0.2417,neighbor_loss:7.4448, Loss: 7.6355\n",
      "Epoch [25/30],reconstruction_loss:0.0705,translation_loss:0.2417,neighbor_loss:7.4419, Loss: 7.6332\n",
      "Epoch [26/30],reconstruction_loss:0.0715,translation_loss:0.2418,neighbor_loss:7.4414, Loss: 7.6337\n",
      "Epoch [27/30],reconstruction_loss:0.0726,translation_loss:0.2418,neighbor_loss:7.4376, Loss: 7.6311\n",
      "Epoch [28/30],reconstruction_loss:0.0729,translation_loss:0.2418,neighbor_loss:7.4368, Loss: 7.6306\n",
      "Epoch [29/30],reconstruction_loss:0.0718,translation_loss:0.2416,neighbor_loss:7.4304, Loss: 7.6231\n",
      "Epoch [30/30],reconstruction_loss:0.0703,translation_loss:0.2414,neighbor_loss:7.4300, Loss: 7.6210\n"
     ]
    }
   ],
   "source": [
    "from contrast.transfomration import TransformationTrainer\n",
    "\n",
    "trainer = TransformationTrainer(X_train1,X_train2, DEVICE)\n",
    "tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train_advanced(num_epochs=30,lambda_similarity=0.1)\n",
    "# tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 7164.31it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 6616.33it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_pred = ref_provider.get_pred(REF_EPOCH, X_train1).argmax(axis=1)\n",
    "tar_pred = tar_provider.get_pred(TAR_EPOCH, X_train2).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505016\n"
     ]
    }
   ],
   "source": [
    "from eval.evaluate import *\n",
    "rate = evaluate_high_dimesion_trans_knn_preserving(tar_mapped, X_train2)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 7398.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reconstructed_pred = tar_provider.get_pred(TAR_EPOCH, ref_reconstructed).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "diff = 0\n",
    "for i in range(len(reconstructed_pred)):\n",
    "    if reconstructed_pred[i] != tar_pred[i]:\n",
    "        diff = diff+1\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff pred number is 41\n",
      "index diff pred number is 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "sub_len = 50000\n",
    "\n",
    "# 1. use cos sim build \n",
    "model = NearestNeighbors(n_neighbors=1, metric='cosine', algorithm='auto').fit(tar_mapped[:sub_len])\n",
    "\n",
    "# 2. find X_train1 most sim point data2_mapped中的最相似点\n",
    "distances, most_similar_points = model.kneighbors(X_train1[:sub_len])\n",
    "\n",
    "most_similar_points = most_similar_points.flatten()  # 将索引数组转为1D\n",
    "\n",
    "# 3. 比较预测值\n",
    "m = np.sum(ref_pred[:sub_len] != tar_pred[most_similar_points])\n",
    "k = np.sum(ref_pred[:sub_len] != tar_pred[:sub_len])\n",
    "\n",
    "print(\"diff pred number is {}\".format(m))\n",
    "print(\"index diff pred number is {}\".format(k))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
