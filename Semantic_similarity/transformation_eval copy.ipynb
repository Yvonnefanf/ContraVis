{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 311.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 3751.18it/s]\n"
     ]
    }
   ],
   "source": [
    "####### dropout resnet18 vs without dropout\n",
    "#### \n",
    "import torch\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "sys.path.append(\"/home/yifan/projects/cophi/ContraVis\")\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/yifan/projects/deepdebugertool/DLVisDebugger\")\n",
    "# REF_PATH = \"/home/yifan/Exp/Noise/0.2/experiment_vis\"\n",
    "# CONFIG_PATH = \"/home/yifan/experiments/noise/20\"\n",
    "# TAR_PATH = \"/home/yifan/dataset/cleanfornoise10\"\n",
    "\n",
    "# # CLEAN_PATH = \"/home/yifan/Exp/Noise/0.2/experiment1\"\n",
    "TAR_PATH = \"/home/yifan/experiments/backdoor/resnet18_CIFAR10/experiment10\"\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "\n",
    "\n",
    "ENCODER_DIMS=[512,256,256,256,256,2]\n",
    "DECODER_DIMS= [2,256,256,256,256,512]\n",
    "VIS_MODEL_NAME = 'vis2'\n",
    "\n",
    "########## initulize reference data and target data\n",
    "from singleVis.DataInit import DataInit\n",
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "DEVICE = \"cuda:1\"\n",
    "tar_datainit = DataInit(TAR_PATH,TAR_PATH,TAR_EPOCH,DEVICE)\n",
    "ref_datainit = DataInit(REF_PATH,REF_PATH,REF_EPOCH,DEVICE)\n",
    "\n",
    "ref_model, ref_provider, ref_train_data, ref_prediction, ref_prediction_res, ref_scores = ref_datainit.getData()\n",
    "tar_model, tar_provider, tar_train_data, tar_prediction, tar_prediction_res, tar_scores = tar_datainit.getData()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 512)\n",
      "(50000, 512)\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import svd  \n",
    "def orthogonal_mapping(data1, data2):\n",
    "        \"\"\"\n",
    "        use Orthogonal Mapping, map data2 to data1's space。\n",
    "    \n",
    "        :param data1: numpy array, shape (n_samples, n_features)\n",
    "        :param data2: numpy array, shape (n_samples, n_features)\n",
    "        :return: data2_mapped: numpy array, mapped data2\n",
    "        \"\"\"\n",
    "        # step1: Centralized data\n",
    "        data1_centered = data1 - np.mean(data1, axis=0)\n",
    "        data2_centered = data2 - np.mean(data2, axis=0)\n",
    "        # step2: Calculate the cross-covariance matrix\n",
    "        C = data2_centered.T @ data1_centered\n",
    "        # step3: singular value decomposition\n",
    "        U, _, Vt = svd(C)\n",
    "\n",
    "        # step4: Compute orthogonal mapping matrix\n",
    "        W = U @ Vt\n",
    "\n",
    "        # step5: Apply mapping matrix\n",
    "        data2_mapped = data2_centered @ W\n",
    "    \n",
    "        return data2_mapped\n",
    "X_train1 = ref_provider.train_representation(REF_EPOCH)\n",
    "X_train2 = tar_provider.train_representation(TAR_EPOCH)\n",
    "X_train2 = X_train2.reshape(X_train2.shape[0],X_train2.shape[1])\n",
    "print(X_train1.shape)\n",
    "print(X_train2.shape)\n",
    "data2_mapped = orthogonal_mapping(X_train1,X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999986666666667\n"
     ]
    }
   ],
   "source": [
    "from eval.evaluate import *\n",
    "rate = evaluate_high_dimesion_trans_knn_preserving(data2_mapped, X_train2)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4549\n",
      "Epoch [21/10], Loss: 0.7660\n",
      "Epoch [41/10], Loss: 0.5967\n",
      "Epoch [61/10], Loss: 0.3762\n",
      "Epoch [81/10], Loss: 0.2366\n",
      "Epoch [101/10], Loss: 0.2019\n",
      "Epoch [121/10], Loss: 0.1954\n",
      "Epoch [141/10], Loss: 0.1917\n",
      "Epoch [161/10], Loss: 0.1904\n",
      "Epoch [181/10], Loss: 0.1894\n",
      "Epoch [1/10],reconstruction_loss:0.0657,translation_loss:0.2451,neighbor_loss:7.4950, Loss: 7.6833\n",
      "Epoch [2/10],reconstruction_loss:0.0655,translation_loss:0.2451,neighbor_loss:7.4906, Loss: 7.6787\n",
      "Epoch [3/10],reconstruction_loss:0.0653,translation_loss:0.2450,neighbor_loss:7.4908, Loss: 7.6786\n",
      "Epoch [4/10],reconstruction_loss:0.0652,translation_loss:0.2449,neighbor_loss:7.4890, Loss: 7.6766\n",
      "Epoch [5/10],reconstruction_loss:0.0651,translation_loss:0.2448,neighbor_loss:7.4860, Loss: 7.6735\n",
      "Epoch [6/10],reconstruction_loss:0.0651,translation_loss:0.2448,neighbor_loss:7.4858, Loss: 7.6733\n",
      "Epoch [7/10],reconstruction_loss:0.0651,translation_loss:0.2447,neighbor_loss:7.4815, Loss: 7.6690\n",
      "Epoch [8/10],reconstruction_loss:0.0652,translation_loss:0.2447,neighbor_loss:7.4816, Loss: 7.6691\n",
      "Epoch [9/10],reconstruction_loss:0.0652,translation_loss:0.2446,neighbor_loss:7.4779, Loss: 7.6654\n",
      "Epoch [10/10],reconstruction_loss:0.0652,translation_loss:0.2445,neighbor_loss:7.4764, Loss: 7.6638\n"
     ]
    }
   ],
   "source": [
    "from contrast.transfomration import TransformationTrainer\n",
    "\n",
    "trainer = TransformationTrainer(X_train1,X_train2, DEVICE)\n",
    "tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train_advanced(base_epoch = 200, num_epochs=10,lambda_similarity=1)\n",
    "# tarns_model,tar_mapped,ref_reconstructed  = trainer.transformation_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38838666666666666\n"
     ]
    }
   ],
   "source": [
    "from eval.evaluate import *\n",
    "rate = evaluate_high_dimesion_trans_knn_preserving(ref_reconstructed, X_train2)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 6546.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar wrong prediction: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tar_pred = tar_provider.get_pred(TAR_EPOCH, X_train2).argmax(axis=1)\n",
    "tar_label = tar_provider.train_labels(TAR_EPOCH)\n",
    "wrong = 0\n",
    "for i in range(len(tar_label)):\n",
    "    if tar_pred[i] !=tar_label[i]:\n",
    "        wrong = wrong + 1\n",
    "print(\"tar wrong prediction:\",wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 8004.46it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 6999.65it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 6839.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref_pred = ref_provider.get_pred(REF_EPOCH, X_train1).argmax(axis=1)\n",
    "tar_pred = tar_provider.get_pred(TAR_EPOCH, X_train2).argmax(axis=1)\n",
    "reconstructed_pred = tar_provider.get_pred(TAR_EPOCH, ref_reconstructed).argmax(axis=1)\n",
    "diff = 0\n",
    "for i in range(len(reconstructed_pred)):\n",
    "    if reconstructed_pred[i] != tar_pred[i]:\n",
    "        diff = diff+1\n",
    "print(\"reconstruct prediction different number:\",diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff pred number is 41\n",
      "index diff pred number is 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "sub_len = 50000\n",
    "\n",
    "# 1. use cos sim build \n",
    "model = NearestNeighbors(n_neighbors=1, metric='cosine', algorithm='auto').fit(tar_mapped[:sub_len])\n",
    "\n",
    "# 2. find X_train1 most sim point data2_mapped中的最相似点\n",
    "distances, most_similar_points = model.kneighbors(X_train1[:sub_len])\n",
    "\n",
    "most_similar_points = most_similar_points.flatten()  # 将索引数组转为1D\n",
    "\n",
    "# 3. 比较预测值\n",
    "m = np.sum(ref_pred[:sub_len] != tar_pred[most_similar_points])\n",
    "k = np.sum(ref_pred[:sub_len] != tar_pred[:sub_len])\n",
    "\n",
    "print(\"diff pred number is {}\".format(m))\n",
    "print(\"index diff pred number is {}\".format(k))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
